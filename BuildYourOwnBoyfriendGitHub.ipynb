{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hu4uY6OprlFt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import json\n",
        "import re\n",
        "from string import Template\n",
        "import random\n",
        "\n",
        "print('Enter OpenAI API key:')\n",
        "openai.api_key = input()\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=openai.api_key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "6GbgKn0ArpFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reocurring function used to save GPT responses as JSONs\n",
        "def save_json(model_output, filename):\n",
        "  output_text = model_output.strip()\n",
        "\n",
        "  #getting rid of the ```json\n",
        "  if output_text.startswith(\"```\"):\n",
        "    output_text = re.sub(r\"^```(?:json)?\\s*\", \"\", output_text)\n",
        "    output_text = re.sub(r\"```$\", \"\", output_text.strip())\n",
        "\n",
        "  try:\n",
        "    data = json.loads(output_text)\n",
        "  except json.JSONDecodeError as e:\n",
        "    print(\"Error:\", e)\n",
        "    #even if it's not in json format it will save it as a .txt file\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(output_text)\n",
        "  else:\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
        "    print(f\"Saved valid JSON as {filename}\")"
      ],
      "metadata": {
        "id": "IsOc2tk6rqnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#recurring function used to get all events\n",
        "def get_events():\n",
        "  events = []\n",
        "  with open(\"table6.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    plot_data = json.load(f)\n",
        "\n",
        "  for node in plot_data.get(\"nodes\", {}).values():\n",
        "    events.extend(node.get(\"edgeEvents\", []))\n",
        "\n",
        "  return events"
      ],
      "metadata": {
        "id": "L0qdrlnXrs8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for now using the .txt files but will later need to fix this to use the fanfics.csv\n",
        "fanfic_path = \"/content/debug_fic_71802996.txt\"\n",
        "with open(fanfic_path, 'r', encoding='utf-8') as file:\n",
        "  fanfic = file.read()"
      ],
      "metadata": {
        "id": "OVjeAMH7rur0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#need to get the plot summaries for the fanfictions\n",
        "prompt = f\"\"\"\n",
        "Tell me who the main character is on the first line in the form of 'char_name = [character name]' and generate a plot summary of {fanfic} in the form of 'summary = [summary]'\n",
        "  \"\"\"\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input= prompt\n",
        "  )\n",
        "print(response.output_text)\n",
        "char_and_sum = \"character_and_summary.txt\"\n",
        "with open(char_and_sum, \"w\", encoding=\"utf-8\") as file:\n",
        "  file.write(response.output_text)"
      ],
      "metadata": {
        "id": "ks5SfyoBrwkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is the JSON schema for generating the tree(plot-to-tree)\n",
        "JSON_SCHEMA = {\n",
        "    \"nodes\": {\n",
        "        \"node_1\": {\n",
        "            \"state\": \"<initial state of {char_name}>\",  # The initial state of the main character (no major plot points).\n",
        "            \"goal\": \"<goal of {char_name} given the current state>\",  # Starts with 'To ...'\n",
        "            \"decision\": \"<key decision taken by {char_name} that propels the story forward>\",  # Starts with '{char_name} decides to ...'\n",
        "            \"edgeEvents\": [\n",
        "                \"<repeat key decision taken by {char_name} that propels the story forward, starting with '{char_name} decides to ...'>\",\n",
        "                \"<event resulting from the key decision and leading to next state>\",\n",
        "                \"<next state of {char_name} resulting from the previous events>\"\n",
        "            ],\n",
        "            \"alternate_decision\": \"<an alternate decision {char_name} could have made given the same state and goal>\"\n",
        "        },\n",
        "        \"node_2\": {\n",
        "            \"state\": \"<state of {char_name} resulting from the previous node's edgeEvents>\",  # The current state of the main character.\n",
        "            \"goal\": \"<goal of {char_name} given the current state>\",  # Starts with 'To ...'\n",
        "            \"decision\": \"<key decision taken by {char_name} that propels the story forward>\",  # Starts with '{char_name} decides to ...'\n",
        "            \"edgeEvents\": [\n",
        "                \"<repeat key decision taken by {char_name} that propels the story forward, starting with '{char_name} decides to ...'>\",\n",
        "                \"<event resulting from the key decision and leading to next state>\",\n",
        "                \"<next state of {char_name} resulting from the previous events>\"\n",
        "            ],\n",
        "            \"alternate_decision\": \"<an alternate decision {char_name} could have made given the same state and goal>\"\n",
        "        },\n",
        "        \"node_3\": {\n",
        "            \"state\": \"<state of {char_name} resulting from the previous node's edgeEvents>\",  # The current state of the main character.\n",
        "            \"goal\": \"<goal of {char_name} given the current state>\",  # Starts with 'To ...'\n",
        "            \"decision\": \"<key decision taken by {char_name} that propels the story forward>\",  # Starts with '{char_name} decides to ...'\n",
        "            \"edgeEvents\": [\n",
        "                \"<repeat key decision taken by {char_name} that propels the story forward, starting with '{char_name} decides to ...'>\",\n",
        "                \"<event resulting from the key decision and leading to next state>\",\n",
        "                \"<next state of {char_name} resulting from the previous events>\"\n",
        "            ],\n",
        "            \"alternate_decision\": \"<an alternate decision {char_name} could have made given the same state and goal>\"\n",
        "        },\n",
        "        \"node_4\": {\n",
        "            \"state\": \"<state of {char_name} resulting from the previous node's edgeEvents>\",  # The current state of the main character.\n",
        "            \"goal\": \"<goal of {char_name} given the current state>\",  # Starts with 'To ...'\n",
        "            \"decision\": \"<key decision taken by {char_name} that propels the story forward>\",  # Starts with '{char_name} decides to ...'\n",
        "            \"edgeEvents\": [\n",
        "                \"<repeat key decision taken by {char_name} that propels the story forward, starting with '{char_name} decides to ...'>\",\n",
        "                \"<event resulting from the key decision and leading to next state>\",\n",
        "                \"<next state of {char_name} resulting from the previous events>\"\n",
        "            ],\n",
        "            \"alternate_decision\": \"<an alternate decision {char_name} could have made given the same state and goal>\"\n",
        "        },\n",
        "        \"node_5\": {\n",
        "            \"state\": \"<state of {char_name} resulting from the previous node's edgeEvents>\",  # The final state setup.\n",
        "            \"goal\": \"<final character goal given the current state>\",  # Starts with 'To ...'\n",
        "            \"decision\": \"<key decision taken by {char_name} that propels the story forward>\",  # Starts with '{char_name} decides to ...'\n",
        "            \"edgeEvents\": [\n",
        "                \"<repeat key decision taken by {char_name} leading to end of story, starting with '{char_name} decides to ...'>\",\n",
        "                \"<event resulting from the key decision and leading to end of story>\",\n",
        "                \"<final state of {char_name} resulting from the previous events>\"\n",
        "            ],\n",
        "            \"alternate_decision\": \"<an alternate decision {char_name} could have made given the same state and goal>\"\n",
        "        },\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "Vc8OBI3iryiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/character_and_summary.txt'\n",
        "#need to get the plot summary and character name generated from .txt\n",
        "variables = {}\n",
        "with open(file_path, \"r\") as f:\n",
        "       for line in f:\n",
        "           parts = line.strip().split(\"=\", 1)\n",
        "           if len(parts) == 2:\n",
        "               key = parts[0].strip()\n",
        "               value = parts[1].strip()\n",
        "               variables[key] = value\n",
        "\n",
        "\n",
        "print(f\"char_name: {variables['char_name']}\")\n",
        "print(f\"summary: {variables['summary']}\")\n",
        "num_nodes = 5\n",
        "\n",
        "#prompting for generating the tree (plot-to-tree)\n",
        "messages2 = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful fiction writer assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": f\"\"\"{variables['summary']}\\n Summarize the plot above into a plot tree of\n",
        "    {'at most 6' if num_nodes == '' else num_nodes}\n",
        "nodes with each node containing the state and goal of {variables['char_name']}, and the key\n",
        "decision that propels the story forward. Each edge should contain a list of\n",
        "events that lead {variables['char_name']} to the state of next node. Also, Given the same\n",
        "state and goal of {variables['char_name']}, imagine an alternate decision that would have led\n",
        "{variables['char_name']} to a different storyline. Output in JSON format with schema:\n",
        "{JSON_SCHEMA}. Make sure that all important plot points are included in\n",
        "'edgeEvents' but not in 'state'\"\"\"\n",
        "}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages= messages2\n",
        "    )\n",
        "print(response.choices[0].message.content)\n",
        "save_json(response.choices[0].message.content, \"table6.json\")"
      ],
      "metadata": {
        "id": "JXNRVVQ_r038"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now need to get events from the nodes to do the next prompt"
      ],
      "metadata": {
        "id": "8k6r-wWur6n2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#JSON schema for extracting key events\n",
        "JSON_SCHEMA = {\n",
        "    \"inciting_incident\": {\n",
        "        \"eventId\": \"<the event number>\",\n",
        "        \"event\": \"<the event corresponding to the inciting incident>\"\n",
        "    },\n",
        "    \"crisis\": {\n",
        "        \"eventId\": \"<the event number>\",\n",
        "        \"event\": \"<the event corresponding to the crisis>\"\n",
        "    },\n",
        "    \"climax\": {\n",
        "        \"eventId\": \"<the event number>\",\n",
        "        \"event\": \"<the event corresponding to the climax>\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "bx1a8Vjkr3xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading in the tree json and looping through the edgeEvents to find the key events\n",
        "events = get_events()\n",
        "events_text = \"\\n\".join(events)\n",
        "print(\"events_text:\", events_text)\n",
        "\n",
        "messages2 = [\n",
        "    {\"role\": \"system\",\"content\": f\"\"\"Here are some definitions in the context of three-act story\n",
        "structure: The inciting incident is an event that pulls the protagonist\n",
        "out of their normal world and into the main action of the story. It is\n",
        "the turning point between Act One and Act Two. The crisis is the moment\n",
        "when the protagonist faces their greatest challenge or obstacle, leading\n",
        "directly to the climax of the story. It is the turning point between Act Two\n",
        "and Act Three. The climax is the climactic confrontation in which the hero\n",
        "faces a point of no return: they must either prevail or perish. It occurs in\n",
        "Act Three and should have the peak tension of the story. You will be given a\n",
        "list of events from a movie plot. Your task is to identify the inciting\n",
        "incident, crisis, and climax. Output in JSON format with schema:\n",
        "{JSON_SCHEMA}.\"\"\"\n",
        "},\n",
        "{\n",
        "\"role\": \"user\", \"content\": f\"{events_text}\"\n",
        "}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages= messages2\n",
        "    )\n",
        "print(response.choices[0].message.content)\n",
        "save_json(response.choices[0].message.content, \"table7.json\")"
      ],
      "metadata": {
        "id": "rUmj4dC9r8U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, we prompt (Table 7) GPT-4 to identify three key events corresponding to the three\n",
        "major plot points ( 2 in Figure 3) from all of the\n",
        "edge events in a storyline and save them for later\n",
        "use in the prompt generation.\n",
        "Generating a prompt for each node"
      ],
      "metadata": {
        "id": "TsL8CtznsBOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#JSON schema for the meta prompting\n",
        "JSON_SCHEMA = {\n",
        "    \"branching_event_number\": \"<branching_event>\",\n",
        "    \"original_decision\": \"<storyline[f'node_{branching_node}']['decision']>\",\n",
        "    \"alternate_decision\": \"<storyline[f'node_{branching_node}']['alternate_decision']>\",\n",
        "    \"new_story_length\": \"<(len(storyline) - branching_node) * 3>\",\n",
        "    \"major_plot_points\": \"<mpp>\",\n",
        "    \"prompt\": (\n",
        "        \"TODO: <a prompt for ChatGPT for every branching point above with the following requirements:\\n\"\n",
        "        \"1. Ask to use the original storyline as a reference to write an alternate \"\n",
        "        \"storyline that branches out at event {branching_event} if {char_name} \"\n",
        "        \"{storyline[f'node_{branching_node}']['alternate_decision']} instead of \"\n",
        "        \"{storyline[f'node_{branching_node}']['decision']}.\\n\"\n",
        "        \"2. Provide 5 thought-provoking, concrete guiding questions as potential directions \"\n",
        "        \"to explore that expand the following:\\n\"\n",
        "        \"   a. How would the alternate decision change or replace {mpp}?\\n\"\n",
        "        \"   b. How would {char_name} make key decisions that overcome new challenges and propel the story forward?\\n\"\n",
        "        \"3. Describe what an ideal alternate storyline should look like.\\n\"\n",
        "        \"4. Ask to output the alternate storyline as a list of \"\n",
        "        \"{(len(storyline) - branching_node + 1) * 3} events that has \"\n",
        "        \"{storyline[f'node_{branching_node}']['alternate_decision']} as the first event.>\"\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "fD_-X6gdr-xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for this prompting need to define branching_event, branching_node,\n",
        "#mpp (is it all or just 1), storyline, branching_node value?\n",
        "\"\"\"\n",
        "With meta-prompts generated for each node of the\n",
        "original storyline, the system recursively branches\n",
        "out at each node and writes the alternate storylines\n",
        "accordingly:\n",
        "\"\"\"\n",
        "with open(\"table6.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    storyline = json.load(f)\n",
        "\n",
        "with open(\"table7.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    key_events = json.load(f)\n",
        "\n",
        "events = get_events()\n",
        "events_text = \"\\n\".join(events)\n",
        "print(\"events_text:\", events_text)\n",
        "\n",
        "inciting_incident_num = int(key_events[\"inciting_incident\"][\"eventId\"])\n",
        "crisis_num = int(key_events[\"crisis\"][\"eventId\"])\n",
        "climax_num = int(key_events[\"climax\"][\"eventId\"])\n",
        "\n",
        "for i in range(num_nodes):\n",
        "  #i is the branching_node\n",
        "  #there are 15 events because there are 5 nodes\n",
        "  #confused if branching_event is correct\n",
        "  random_integer = random.randint(0, 2)\n",
        "  branching_event = events[i+4]\n",
        "  decision = storyline[\"nodes\"][f\"node_{i+1}\"][\"decision\"]\n",
        "  alternate_decision = storyline[\"nodes\"][f\"node_{i+1}\"][\"alternate_decision\"]\n",
        "\n",
        "  if i < inciting_incident_num:\n",
        "    mpp = key_events[\"inciting_incident\"][\"event\"]\n",
        "  elif i < crisis_num:\n",
        "    mpp = key_events[\"crisis\"][\"event\"]\n",
        "  elif i < climax_num:\n",
        "    mpp = key_events[\"climax\"][\"event\"]\n",
        "  else:\n",
        "    print(\"print\")\n",
        "  messages2 = [\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert in prompting ChatGPT.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Original storyline:\n",
        "{events_text}\n",
        "\n",
        "Write a prompt for ChatGPT with the following requirements:\n",
        "1. Ask to use the original storyline as a reference to write an alternate storyline that branches out at event {branching_event} if {variables['char_name']} {alternate_decision} instead of {decision}.\n",
        "2. Provide 5 thought-provoking concrete guiding questions as potential directions to explore that expand the following:\n",
        "   a. How would the alternate decision change or replace {mpp}?\n",
        "   b. How would {variables['char_name']} make key decisions that overcome new challenges and propel the story forward?\n",
        "3. Describe what an ideal alternate storyline should look like.\n",
        "4. Ask to output the alternate storyline as a list of {(15 - i + 1) * 3} events that has {alternate_decision} as the first event.\n",
        "\n",
        "Output the prompt with the following JSON schema: {JSON_SCHEMA}\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=messages2\n",
        "    )\n",
        "\n",
        "  print(response.choices[0].message.content)\n",
        "  save_json(response.choices[0].message.content, f\"table8_node{i}.json\")\n",
        "\n",
        "  #need to fix the new_story_length and branching_event number"
      ],
      "metadata": {
        "id": "IbaKBoLfsDh-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}